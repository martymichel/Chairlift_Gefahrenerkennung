{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "632634e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46294264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadVideo():\n",
    "    # Laden des Videos\n",
    "    video_path = r'C:\\Users\\mtwar\\Documents\\MAS Data Science\\CAS Machine Intelligence\\Deep Learning\\LNW\\5_Video\\WhatsApp Video 2025-05-12 at 11.45.15.mp4'\n",
    "    #cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Setze die Startposition auf 15 Sekunden (15000 Millisekunden)\n",
    "    #start_time_ms = 15000\n",
    "    #cap.set(cv2.CAP_PROP_POS_MSEC, start_time_ms)\n",
    "\n",
    "    #video_path = r'C:\\Users\\mtwar\\Documents\\MAS Data Science\\CAS Machine Intelligence\\Deep Learning\\LNW\\5_Video\\WhatsApp Video 2025-05-12 at 11.45.35.mp4'\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    return cap\n",
    "\n",
    "def loadVideoPath():\n",
    "    # Laden des Videos\n",
    "    video_path = r'C:\\Users\\mtwar\\Documents\\MAS Data Science\\CAS Machine Intelligence\\Deep Learning\\LNW\\5_Video\\WhatsApp Video 2025-05-12 at 11.45.15.mp4'\n",
    "    #cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Setze die Startposition auf 15 Sekunden (15000 Millisekunden)\n",
    "    #start_time_ms = 15000\n",
    "    #cap.set(cv2.CAP_PROP_POS_MSEC, start_time_ms)\n",
    "\n",
    "    #video_path = r'C:\\Users\\mtwar\\Documents\\MAS Data Science\\CAS Machine Intelligence\\Deep Learning\\LNW\\5_Video\\WhatsApp Video 2025-05-12 at 11.45.35.mp4'\n",
    "    return video_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11cc7a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = loadVideo()\n",
    "\n",
    "# Erstellen des Hintergrundsubtraktors\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=100, detectShadows=False)\n",
    "\n",
    "# Original-Framerate des Videos\n",
    "original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_delay = int(1000 / original_fps)  # Verzögerung in Millisekunden\n",
    "\n",
    "while cap.isOpened():\n",
    "    start_time = time.time()\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Hintergrundsubtraktion anwenden\n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    # Morphologische Operationen zur Verbesserung des Masks\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Konturen finden\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) < 500:  # Ignorieren kleiner Konturen\n",
    "            continue\n",
    "\n",
    "        # Umgebende Box zeichnen\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Vertikales Stapeln der Frames\n",
    "    stacked_frame = np.vstack((frame, cv2.cvtColor(fgmask, cv2.COLOR_GRAY2BGR)))\n",
    "\n",
    "    # Anzeigen des gestapelten Frames\n",
    "    cv2.imshow('Stacked Frames', stacked_frame)\n",
    "\n",
    "    # Berechnung der Zeit, die für die Verarbeitung benötigt wurde\n",
    "    processing_time = int((time.time() - start_time) * 1000)\n",
    "\n",
    "    # Warten, um die ursprüngliche Framerate beizubehalten\n",
    "    if processing_time < frame_delay:\n",
    "        cv2.waitKey(frame_delay - processing_time)\n",
    "    else:\n",
    "        # Wenn die Verarbeitung länger dauert als die Frame-Zeit, einfach zum nächsten Frame gehen\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39543542",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = loadVideo()\n",
    "\n",
    "# Überprüfen, ob das Video erfolgreich geöffnet wurde\n",
    "if not cap.isOpened():\n",
    "    print(\"Fehler beim Öffnen der Videodatei\")\n",
    "    exit()\n",
    "\n",
    "# Erstellen des Hintergrundsubtraktors\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=100, detectShadows=False)\n",
    "\n",
    "# Original-Framerate des Videos\n",
    "original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_delay = int(1000 / original_fps)  # Verzögerung in Millisekunden\n",
    "\n",
    "while cap.isOpened():\n",
    "    start_time = time.time()\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Hintergrundsubtraktion anwenden\n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    # Morphologische Operationen zur Verbesserung der Maske\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Konturen finden\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Zeichnen der Konturen auf dem Original-Frame\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) < 500:  # Ignorieren kleiner Konturen\n",
    "            continue\n",
    "\n",
    "        # Umgebende Box zeichnen\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Anzeigen des Frames mit den erkannten Objekten\n",
    "    cv2.imshow('Frame with Detected Objects', frame)\n",
    "\n",
    "    # Berechnung der Zeit, die für die Verarbeitung benötigt wurde\n",
    "    processing_time = int((time.time() - start_time) * 1000)\n",
    "\n",
    "    # Warten, um die ursprüngliche Framerate beizubehalten\n",
    "    if processing_time < frame_delay:\n",
    "        cv2.waitKey(frame_delay - processing_time)\n",
    "    else:\n",
    "        # Wenn die Verarbeitung länger dauert als die Frame-Zeit, einfach zum nächsten Frame gehen\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Freigabe der Ressourcen\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d3b0e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.VideoPlayer at 0x257b733c620>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "class VideoPlayer:\n",
    "    def __init__(self, video_source):\n",
    "        self.cap = cv2.VideoCapture(video_source)\n",
    "        if not self.cap.isOpened():\n",
    "            raise ValueError(\"Unable to open video source\", video_source)\n",
    "\n",
    "        self.history = 500\n",
    "        self.varThreshold = 100\n",
    "\n",
    "        self.fgbg = cv2.createBackgroundSubtractorMOG2(\n",
    "            history=self.history, varThreshold=self.varThreshold, detectShadows=False)\n",
    "\n",
    "        self.original_fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "        self.frame_delay = int(1000 / self.original_fps)\n",
    "\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Video Player\")\n",
    "\n",
    "        self.canvas = tk.Canvas(self.root, width=self.cap.get(cv2.CAP_PROP_FRAME_WIDTH),\n",
    "                                height=self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT)*2)\n",
    "        self.canvas.pack()\n",
    "\n",
    "         # History Slider\n",
    "        self.history_label = tk.Label(self.root, text=\"History\")\n",
    "        self.history_label.pack()\n",
    "        self.history_slider = ttk.Scale(self.root, from_=1, to=1000, orient=tk.HORIZONTAL,\n",
    "                                        command=self.update_history)\n",
    "        self.history_slider.set(self.history)\n",
    "        self.history_slider.pack(fill=tk.X)\n",
    "\n",
    "        # Threshold Slider\n",
    "        self.threshold_label = tk.Label(self.root, text=\"Threshold\")\n",
    "        self.threshold_label.pack()\n",
    "        self.varThreshold_slider = ttk.Scale(self.root, from_=1, to=200, orient=tk.HORIZONTAL,\n",
    "                                             command=self.update_varThreshold)\n",
    "        self.varThreshold_slider.set(self.varThreshold)\n",
    "        self.varThreshold_slider.pack(fill=tk.X)\n",
    "\n",
    "        self.update()\n",
    "\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def update_history(self, value):\n",
    "        self.history = int(float(value))\n",
    "        self.update_bg_subtractor()\n",
    "\n",
    "    def update_varThreshold(self, value):\n",
    "        self.varThreshold = int(float(value))\n",
    "        self.update_bg_subtractor()\n",
    "\n",
    "    def update_bg_subtractor(self):\n",
    "        self.fgbg = cv2.createBackgroundSubtractorMOG2(\n",
    "            history=self.history, varThreshold=self.varThreshold, detectShadows=False)\n",
    "\n",
    "    def update(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret:\n",
    "            fgmask = self.fgbg.apply(frame)\n",
    "            kernel = np.ones((5, 5), np.uint8)\n",
    "            fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "            contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            for contour in contours:\n",
    "                if cv2.contourArea(contour) < 500:\n",
    "                    continue\n",
    "                (x, y, w, h) = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            stacked_frame = np.vstack((frame, cv2.cvtColor(fgmask, cv2.COLOR_GRAY2BGR)))\n",
    "            stacked_frame = cv2.cvtColor(stacked_frame, cv2.COLOR_BGR2RGB)\n",
    "            img = ImageTk.PhotoImage(image=Image.fromarray(stacked_frame))\n",
    "\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=img)\n",
    "            self.canvas.image = img\n",
    "        else:\n",
    "            self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            ret, frame = self.cap.read()\n",
    "\n",
    "        self.root.after(self.frame_delay, self.update)\n",
    "\n",
    "# Ersetze 'your_video.mp4' mit dem Pfad zu deinem Video\n",
    "VideoPlayer(loadVideoPath())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be92b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = loadVideo()\n",
    "\n",
    "#  Standardparameter\n",
    "history = 500\n",
    "varThreshold = 16\n",
    "algo = 'MOG2'\n",
    "\n",
    "# Hintergrundsubtraktor initialisieren\n",
    "def initialize_subtractor(algo, history, varThreshold):\n",
    "    if algo == 'MOG2':\n",
    "        return cv2.createBackgroundSubtractorMOG2(history=history, varThreshold=varThreshold, detectShadows=False)\n",
    "    elif algo == 'KNN':\n",
    "        return cv2.createBackgroundSubtractorKNN(history=history, dist2Threshold=varThreshold, detectShadows=False)\n",
    "    else:\n",
    "        return cv2.createBackgroundSubtractorMOG2(history=history, nmixtures=3, backgroundRatio=0.7, noiseSigma=0)\n",
    "\n",
    "fgbg = initialize_subtractor(algo, history, varThreshold)\n",
    "\n",
    "# Callback-Funktion für die Schieberegler\n",
    "def on_history_change(val):\n",
    "    global history, fgbg\n",
    "    history = val\n",
    "    fgbg = initialize_subtractor(algo, history, varThreshold)\n",
    "\n",
    "def on_threshold_change(val):\n",
    "    global varThreshold, fgbg\n",
    "    varThreshold = val\n",
    "    fgbg = initialize_subtractor(algo, history, varThreshold)\n",
    "\n",
    "# Hauptfenster erstellen\n",
    "cv2.namedWindow('Frame')\n",
    "cv2.createTrackbar('History', 'Frame', history, 1000, on_history_change)\n",
    "cv2.createTrackbar('Threshold', 'Frame', varThreshold, 255, on_threshold_change)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        # Wenn das Video zu Ende ist, setzen Sie es zurück\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        continue\n",
    "\n",
    "    # Hintergrundsubtraktion anwenden\n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    # Morphologische Operationen zur Verbesserung der Maske\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Konturen finden\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Zeichnen der Konturen\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) < 500:  # Ignorieren kleiner Konturen\n",
    "            continue\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Anzeigen des Frames\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    # Tastatursteuerung für Algorithmusauswahl\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('1'):\n",
    "        algo = 'KNN'\n",
    "        fgbg = initialize_subtractor(algo, history, varThreshold)\n",
    "    elif key == ord('2'):\n",
    "        algo = 'MOG2'\n",
    "        fgbg = initialize_subtractor(algo, history, varThreshold)\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Aufräumen\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37341f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
